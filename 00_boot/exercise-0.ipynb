{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Boot Camp\n",
    "\n",
    "***\n",
    "\n",
    "## Table of contents:\n",
    "\n",
    "* [Images as arrays](#first)   \n",
    "* [Image color space](#second)\n",
    "* [Image data types](#third)\n",
    "* [Plotting images](#fourth)\n",
    "* [Images in Deep Learning frameworks](#fifth)\n",
    "* [Simple image manipulation](#sixth)\n",
    "* [Loading a set of images](#seventh)\n",
    "* [Segmentation maps](#eighth)\n",
    "* [Batching](#ninth)\n",
    "* [Data augmentation](#tenth)\n",
    "* [Using Tensorboard](#eleventh)\n",
    "* [Convolutions](#twelveth)\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "In this notebook, we will go through some basic image processing in Python and familiarize ourselves with different utilities that can be useful for any Deep Learning pipeline, utilities provides through libraries like `skimage`, `imgaug`, `tensorboard`, `glob`, `tqdm` and more.\n",
    "\n",
    "We will be using sample images from this [three-dimensional X-ray microtomography thalamocortical dataset](https://github.com/nerdslab/xray-thc), used to characterize brain heterogeneity. These samples, imaged in the Striatum and Hypothalamus regions of a mouse brain, were annotated to get microstructure segmentation maps (of cell bodies, blood vessels, and myelinated axons). The full dataset is available on [bossdb](https://bossdb.org/project/prasad2020)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as arrays <a class=\"anchor\" id=\"first\"></a>\n",
    "\n",
    "Images are represented as numpy arrays of shape (height, width, channels).\n",
    "\n",
    "![RGB image as a numpy array](./assets/image_as_array.png)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://e2eml.school/convert_rgb_to_grayscale.html\">Brandon Rohrerâ€™s Blog</a></div>\n",
    "\n",
    "\n",
    "Multiple utilities exist to read images from files in Python,\n",
    "we will use `skimage.io.imread`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "img = io.imread('data/img_650_1162__600_1112__0.tiff')\n",
    "print('Type:', type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image color space <a class=\"anchor\" id=\"second\"></a>\n",
    "If the image is in grayscale, then the number of channels is equal to 1,\n",
    "in which case the array can also be of shape (height, width).\n",
    "If the image is RGB, then the number of channels is 3\n",
    "with each channel encoding the red, green and blue components.\n",
    "\n",
    "**Q: Is `img` RGB or Grayscale?**\n",
    "\n",
    "<div style=\"text-align: right\"> Help: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">Numpy cheatsheet</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Reshape the image such that its shape is (height, width, 1)**\n",
    "\n",
    "<div style=\"text-align: right\"> Hint: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\">expand dims</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data types <a class=\"anchor\" id=\"third\"></a>\n",
    "\n",
    "\n",
    "Images can be represented by a variety of data types. The following is a list of the most common types:\n",
    "- `bool`: binary, 0 or 1\n",
    "- `uint8`: unsigned integers, 0 to 255 range\n",
    "- `float`: -1 to 1 or 0 to 1\n",
    "\n",
    "**Q: What is the data type of `img`? What are the minimum and maximum intensity values?**\n",
    "<div style=\"text-align: right\"> Help: <a href=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\">Numpy cheatsheet</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images <a class=\"anchor\" id=\"fourth\"></a>\n",
    "\n",
    "Using `matplotlib` we can visualize the image. When the image is in grayscale,\n",
    "a colormap can be specified using the `cmap` argument. By default,\n",
    "the colormap is `viridis`, we will use `gray`.\n",
    "\n",
    "> Useful `matplotlib` ressources:\n",
    "> - [matplotlib cheatsheets](https://github.com/matplotlib/cheatsheets)\n",
    "> - [colormaps in matplotlib](https://matplotlib.org/stable/tutorials/colors/colormaps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Images in Deep Learning frameworks <a class=\"anchor\" id=\"fifth\"></a>\n",
    "\n",
    "\n",
    "In pytorch, tensorflow or jax, images are represented as (channels, height, width)\n",
    "and are rescaled to be in the [0, 1] range.\n",
    "\n",
    "**Q: Generate a new image that respects these conventions.\n",
    "You can use [`np.transpose`](https://numpy.org/doc/stable/reference/generated/numpy.transpose.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple image manipulation <a class=\"anchor\" id=\"sixth\"></a>\n",
    "\n",
    "Given that images are numpy arrays, we can take advantage of the powerful\n",
    " [indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html)\n",
    " to perform simple transformations like cropping, downsampling and flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cropping\n",
    "cropped_img = img[10:310, 50:350]\n",
    "\n",
    "# downsampling\n",
    "factor = 2\n",
    "downsampled_img = img[::factor, ::factor]\n",
    "\n",
    "# horizontal flip\n",
    "hflip_img = img[:,::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5), frameon=False)\n",
    "\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[0].set_title('Original image\\nSize = {}'.format(str(img.shape)))\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(cropped_img, cmap='gray')\n",
    "axs[1].set_title('Cropped image\\nSize = {}'.format(str(cropped_img.shape)))\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(downsampled_img, cmap='gray')\n",
    "axs[2].set_title('Downsampled image\\nSize = {}'.format(str(downsampled_img.shape)))\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(hflip_img, cmap='gray')\n",
    "axs[3].set_title('Horizontal Flip\\n Size = {}'.format(str(hflip_img.shape)))\n",
    "axs[3].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Apply the following transformations:**\n",
    "- Center crop of size (256, 256)\n",
    "- Vertical flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a set of images <a class=\"anchor\" id=\"seventh\"></a>\n",
    "\n",
    "Given a set of images in a folder, we need to be able to easily find the pathnames and load them in. \n",
    "`glob` is a standard package that provides a utility for finding all pathnames that match a given pattern.\n",
    "\n",
    "Here our images have the `.tiff` extenstion and all start with `img`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "root = 'data/'\n",
    "img_filenames = glob(os.path.join(root, 'img*.tiff'))\n",
    "\n",
    "print('Found:')\n",
    "for img_filename in img_filenames:\n",
    "    print(' ', img_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the images.\n",
    "\n",
    "We will use `tqdm` to track progress (even though we only have a small number of images here). `tqdm` provides a progress bar that simply wraps around any iterable, making it useful for tracking training progress for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "imgs = []\n",
    "for fname in tqdm(img_filenames):\n",
    "    img = io.imread(fname)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    imgs.append(img)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "for i in range(4):\n",
    "    axs[i].imshow(imgs[i], cmap='gray')\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation maps <a class=\"anchor\" id=\"eighth\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition to the image files, you will also find the corresponding segmentation files. \n",
    "\n",
    "**Q: Using what we have seen thus far, load the segmentation maps into a list called `seg_maps` and visualize them. Be careful with the file ordering.**\n",
    "<div style=\"text-align: right\"> <a href=\"https://pythonbasics.org/replace/\">Hint</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_maps = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that there are 4 unique values in the segmentation maps, each corresponding to one of these four classes:\n",
    "- 0: background\n",
    "- 1: cell\n",
    "- 2: blood vessel\n",
    "- 3: axon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching <a class=\"anchor\" id=\"ninth\"></a>\n",
    "\n",
    "Mini-batch stochastic gradient descent is commonly used during the training of networks.\n",
    "A batch of $B$ images is fed to the model. The input shape will thus get an additional batch dimension at the first dimension: (batch_size, channels, height, width).\n",
    "\n",
    "**Q: Make a batch out of the four images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data augmentation <a class=\"anchor\" id=\"tenth\"></a>\n",
    "\n",
    "Data augmentation (DA) is an important component of Deep Learning.\n",
    "By generating a larger set of training examples, DA helps with generalization.\n",
    "\n",
    "`imgaug` is a Python library that provides a very extensive set of image augmentations,\n",
    "and that seamlessly handles complex annotations like segmentation maps, bounding boxes or keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# fix the random seed\n",
    "ia.seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Augmenting an image\n",
    "To use an augmentation, we can instantiate an `Augmenter` with a set of hyperparamters.\n",
    "With affine transforamtions for example, we can specify the range of the rotation angle to be `(-45, 45)`.\n",
    "\n",
    "In `imgaug`, the channel-axis is always expected to be the last axis and may be skipped for grayscale images, it is\n",
    "also recommended to work with the `uint8` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rotate = iaa.Affine(rotate=(-45, 45))\n",
    "img_aug = rotate(image=imgs[0])\n",
    "\n",
    "plt.imshow(img_aug, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Try running the previous cell again.\n",
    "\n",
    "#### Augmenting image AND segmentation map\n",
    "\n",
    "When applying certain augmentations, we want to make sure that the segmentation map is changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# convert array to SegmentationMapsOnImage instance\n",
    "seg_map = SegmentationMapsOnImage(seg_maps[0], shape=imgs[0].shape)\n",
    "# augment\n",
    "img_aug, seg_map_aug = rotate(image=imgs[0], segmentation_maps=seg_map)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,5))\n",
    "axs[0].imshow(img_aug, cmap='gray')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(seg_map_aug.draw()[0], cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying multiple augmentations\n",
    "We can compose multiple augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 30)),\n",
    "    iaa.pillike.FilterEdgeEnhanceMore(),\n",
    "    iaa.Crop(percent=(0., 0.2))\n",
    "])\n",
    "\n",
    "imgs_aug = seq(images=imgs)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20,10))\n",
    "axs[0].imshow(np.concatenate((imgs), axis=1), cmap='gray')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(np.concatenate((imgs_aug), axis=1), cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q: Famalirize yourself with the different augmentations available through `imgaug`. Refer to the [examples](https://github.com/aleju/imgaug) and the [documentation](https://imgaug.readthedocs.io/en/latest/). Identify and apply augmentations that you think are interesting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorboard <a class=\"anchor\" id=\"eleventh\"></a>\n",
    "\n",
    "TensorBoard is a powerful visualization toolkit for machine learning experimentation. TensorBoard allows tracking metrics such as loss and accuracy, displaying images during training and much more.\n",
    "\n",
    "- Using Tensorboard in PyTorch: https://pytorch.org/docs/stable/tensorboard.html\n",
    "- Using Tensorboard in TensorFlow/keras: https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image('image', imgs[0], global_step=0, dataformats='HWC')\n",
    "writer.add_image('ground_truth_segmentation', seg_maps[0], global_step=0, dataformats='HW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, start TensorBoard:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "and go to the URL it provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions <a class=\"anchor\" id=\"twelveth\"></a>\n",
    "\n",
    "Convolutions are the elementary operations used in CNNs. The image (and later, the feature maps) are convolved with multiple kernels which weights are learned. Below is a visual of the pixel values in the output matrix (green) being computed from neighboring pixels in the input matrix (blue). \n",
    "\n",
    "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif)\n",
    "\n",
    "<div style=\"text-align: right\"> Credit: <a href=\"https://github.com/vdumoulin/conv_arithmetic\">Vincent Dumoulin, Francesco Visin</a></div>\n",
    "\n",
    "**Q: Implement a function that performs \"convolution\". Assume that your image is square and that your kernel is square and has an odd width. Note that your output image will be smaller.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, kernel):\n",
    "    m = img.shape[0]  #size of original image\n",
    "    k = kernel.shape[0]  #size of filter\n",
    "    \n",
    "    mc = ... #size of the new image after convolution\n",
    "    conv_img = np.zeros((mc,mc))\n",
    "    \n",
    "    # perform convolution\n",
    "    for ii in range(mc):\n",
    "        for jj in range(mc):\n",
    "            ...\n",
    "    \n",
    "    return conv_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing filter\n",
    "Convolving the image with a smoothing filter is equivalent to replacing the value of each pixel with the average pixel value within a window of size $dxd$ around it.\n",
    "\n",
    "**Q: Design a smoothing filter. Try different values of d.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What is the effect of this filter?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel filter\n",
    "The following is known as the Sobel filter:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 1 \\\\\n",
    "    0 & 0 & 0 \\\\\n",
    "    -1 & -2 & -1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Q: Apply the Sobel filter and describe what it does**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
